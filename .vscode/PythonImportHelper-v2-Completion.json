[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "EasyID3",
        "importPath": "mutagen.easyid3",
        "description": "mutagen.easyid3",
        "isExtraImport": true,
        "detail": "mutagen.easyid3",
        "documentation": {}
    },
    {
        "label": "FLAC",
        "importPath": "mutagen.flac",
        "description": "mutagen.flac",
        "isExtraImport": true,
        "detail": "mutagen.flac",
        "documentation": {}
    },
    {
        "label": "MP3",
        "importPath": "mutagen.mp3",
        "description": "mutagen.mp3",
        "isExtraImport": true,
        "detail": "mutagen.mp3",
        "documentation": {}
    },
    {
        "label": "WavPack",
        "importPath": "mutagen.wavpack",
        "description": "mutagen.wavpack",
        "isExtraImport": true,
        "detail": "mutagen.wavpack",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "humanize",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "humanize",
        "description": "humanize",
        "detail": "humanize",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "PdfFileReader",
        "importPath": "PyPDF2",
        "description": "PyPDF2",
        "isExtraImport": true,
        "detail": "PyPDF2",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "VideoFileClip",
        "importPath": "moviepy.editor",
        "description": "moviepy.editor",
        "isExtraImport": true,
        "detail": "moviepy.editor",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "pkg_resources",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pkg_resources",
        "description": "pkg_resources",
        "detail": "pkg_resources",
        "documentation": {}
    },
    {
        "label": "nltk",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "nltk",
        "description": "nltk",
        "detail": "nltk",
        "documentation": {}
    },
    {
        "label": "word_tokenize",
        "importPath": "nltk.tokenize",
        "description": "nltk.tokenize",
        "isExtraImport": true,
        "detail": "nltk.tokenize",
        "documentation": {}
    },
    {
        "label": "PorterStemmer",
        "importPath": "nltk.stem",
        "description": "nltk.stem",
        "isExtraImport": true,
        "detail": "nltk.stem",
        "documentation": {}
    },
    {
        "label": "tokenize",
        "importPath": "utils.preprocessing",
        "description": "utils.preprocessing",
        "isExtraImport": true,
        "detail": "utils.preprocessing",
        "documentation": {}
    },
    {
        "label": "stem",
        "importPath": "utils.preprocessing",
        "description": "utils.preprocessing",
        "isExtraImport": true,
        "detail": "utils.preprocessing",
        "documentation": {}
    },
    {
        "label": "extract_audio_metadata",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "peekOfCode": "def extract_audio_metadata(file_path):\n    \"\"\"\n    Extracts metadata from an audio file.\n    Supports various formats like mp3, flac, wavpack, etc.\n    \"\"\"\n    metadata = {}\n    try:\n        if file_path.endswith('.mp3'):\n            audio = MP3(file_path, ID3=EasyID3)\n        elif file_path.endswith('.flac'):",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "save_metadata",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "peekOfCode": "def save_metadata(metadata, save_path):\n    \"\"\"\n    Saves the extracted metadata to a file in JSON format.\n    \"\"\"\n    with open(save_path, 'w') as f:\n        json.dump(metadata, f, indent=4)\ndef process_audio_files(audio_dir, metadata_dir):\n    audio_files = [f for f in os.listdir(audio_dir) if f.endswith(('.mp3', '.flac', '.wv'))] # Extend for other formats\n    with tqdm(total=len(audio_files), unit='file', desc=\"Processing Audio Files\") as pbar:\n        for file in audio_files:",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "process_audio_files",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "peekOfCode": "def process_audio_files(audio_dir, metadata_dir):\n    audio_files = [f for f in os.listdir(audio_dir) if f.endswith(('.mp3', '.flac', '.wv'))] # Extend for other formats\n    with tqdm(total=len(audio_files), unit='file', desc=\"Processing Audio Files\") as pbar:\n        for file in audio_files:\n            file_path = os.path.join(audio_dir, file)\n            file_size = os.path.getsize(file_path)\n            print(f\"Processing {file} (Size: {humanize.naturalsize(file_size)})\")\n            metadata = extract_audio_metadata(file_path)\n            if metadata:\n                save_path = os.path.join(metadata_dir, os.path.basename(file) + '.json')",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "peekOfCode": "def main():\n    audio_dir = 'path/to/audio/files'\n    metadata_dir = 'path/to/ParsedData/AudioMetadata'\n    process_audio_files(audio_dir, metadata_dir)\nif __name__ == '__main__':\n    main()",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "extract_image_metadata",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "peekOfCode": "def extract_image_metadata(file_path):\n    \"\"\"\n    Extracts metadata from an image file.\n    Supported formats: JPEG, PNG, etc.\n    \"\"\"\n    try:\n        with Image.open(file_path) as img:\n            metadata = {\n                \"format\": img.format,\n                \"size\": img.size,",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "save_metadata",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "peekOfCode": "def save_metadata(metadata, save_path):\n    \"\"\"\n    Saves the extracted metadata to a file in JSON format.\n    \"\"\"\n    with open(save_path, 'w') as f:\n        json.dump(metadata, f, indent=4)\ndef process_image_files(image_dir, metadata_dir):\n    image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))] # Add more formats if needed\n    with tqdm(total=len(image_files), unit='file', desc=\"Processing Image Files\") as pbar:\n        for file in image_files:",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "process_image_files",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "peekOfCode": "def process_image_files(image_dir, metadata_dir):\n    image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))] # Add more formats if needed\n    with tqdm(total=len(image_files), unit='file', desc=\"Processing Image Files\") as pbar:\n        for file in image_files:\n            file_path = os.path.join(image_dir, file)\n            file_size = os.path.getsize(file_path)\n            print(f\"Processing {file} (Size: {humanize.naturalsize(file_size)})\")\n            metadata = extract_image_metadata(file_path)\n            if metadata:\n                save_path = os.path.join(metadata_dir, os.path.basename(file) + '.json')",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "peekOfCode": "def main():\n    image_dir = 'path/to/image/files'\n    metadata_dir = 'path/to/ParsedData/ImageMetadata'\n    process_image_files(image_dir, metadata_dir)\nif __name__ == '__main__':\n    main()",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "extract_text_from_pdf",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "peekOfCode": "def extract_text_from_pdf(input_file, output_file):\n    \"\"\"\n    Extracts text from a PDF file and writes it to an output file.\n    Args:\n        input_file (str): The path to the input PDF file.\n        output_file (str): The path to the output file where the extracted text will be written.\n    Raises:\n        FileNotFoundError: If the input file does not exist.\n    \"\"\"\n    try:",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "peekOfCode": "def main():\n    \"\"\"\n    Extracts text from PDF files in a specified directory and saves the extracted text as separate text files.\n    Args:\n        None\n    Returns:\n        None\n    \"\"\"\n    logging.basicConfig(filename='pdf_extraction.log', level=logging.INFO)\n    sorted_pdf_dir = '/home/ncacord/Desktop/raphael_core/AI_Core/DataOrganizerAI/SortedFiles/PDFs'  # Placeholder for PDFs directory",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "documentation": {}
    },
    {
        "label": "parse_text_file",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "peekOfCode": "def parse_text_file(file_path, output_dir):\n    \"\"\"\n    Parse a text file and save the content to a new file in the specified output directory.\n    Args:\n        file_path (str): The path to the input text file.\n        output_dir (str): The directory where the parsed file will be saved.\n    Raises:\n        FileNotFoundError: If the input file is not found.\n        IOError: If an IO error occurs while parsing the file.\n        UnicodeDecodeError: If a Unicode decode error occurs while parsing the file.",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "peekOfCode": "def main():\n    \"\"\"\n    Main function to parse text files in the sorted_docs_dir and save the parsed files in the parsed_output_dir.\n    \"\"\"\n    if not os.path.exists(parsed_output_dir):\n        os.makedirs(parsed_output_dir)\n    files = [filename for filename in os.listdir(sorted_docs_dir) if filename.endswith('.txt')]\n    total_files = len(files)\n    start_time = time.time()\n    with tqdm(total=total_files, ncols=80, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "documentation": {}
    },
    {
        "label": "BASE_DIR",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "peekOfCode": "BASE_DIR = '/home/ncacord/Desktop/raphael_core/AI_Core/DataOrganizerAI'\nsorted_docs_dir = os.path.join(BASE_DIR, 'SortedFiles/Documents')\nparsed_output_dir = os.path.join(BASE_DIR, 'ParsedData/TextData')\nlog_file = os.path.join(BASE_DIR, 'Logs/ParsingLogs/text_parsing.log')\nlogging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s %(message)s')\ndef parse_text_file(file_path, output_dir):\n    \"\"\"\n    Parse a text file and save the content to a new file in the specified output directory.\n    Args:\n        file_path (str): The path to the input text file.",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "documentation": {}
    },
    {
        "label": "sorted_docs_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "peekOfCode": "sorted_docs_dir = os.path.join(BASE_DIR, 'SortedFiles/Documents')\nparsed_output_dir = os.path.join(BASE_DIR, 'ParsedData/TextData')\nlog_file = os.path.join(BASE_DIR, 'Logs/ParsingLogs/text_parsing.log')\nlogging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s %(message)s')\ndef parse_text_file(file_path, output_dir):\n    \"\"\"\n    Parse a text file and save the content to a new file in the specified output directory.\n    Args:\n        file_path (str): The path to the input text file.\n        output_dir (str): The directory where the parsed file will be saved.",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "documentation": {}
    },
    {
        "label": "parsed_output_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "peekOfCode": "parsed_output_dir = os.path.join(BASE_DIR, 'ParsedData/TextData')\nlog_file = os.path.join(BASE_DIR, 'Logs/ParsingLogs/text_parsing.log')\nlogging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s %(message)s')\ndef parse_text_file(file_path, output_dir):\n    \"\"\"\n    Parse a text file and save the content to a new file in the specified output directory.\n    Args:\n        file_path (str): The path to the input text file.\n        output_dir (str): The directory where the parsed file will be saved.\n    Raises:",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "documentation": {}
    },
    {
        "label": "log_file",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "peekOfCode": "log_file = os.path.join(BASE_DIR, 'Logs/ParsingLogs/text_parsing.log')\nlogging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s %(message)s')\ndef parse_text_file(file_path, output_dir):\n    \"\"\"\n    Parse a text file and save the content to a new file in the specified output directory.\n    Args:\n        file_path (str): The path to the input text file.\n        output_dir (str): The directory where the parsed file will be saved.\n    Raises:\n        FileNotFoundError: If the input file is not found.",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "documentation": {}
    },
    {
        "label": "extract_video_metadata",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "peekOfCode": "def extract_video_metadata(video_path, output_dir):\n    try:\n        with VideoFileClip(video_path) as clip:\n            metadata = clip.reader.infos\n        output_file_path = os.path.join(output_dir, os.path.basename(video_path) + '.json')\n        with open(output_file_path, 'w') as file:\n            json.dump(metadata, file)\n        logging.info(\"Metadata extracted for: %s\", video_path)\n        return True\n    except Exception as e:",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "peekOfCode": "def main():\n    logging.basicConfig(filename='video_metadata_extraction.log', level=logging.INFO)\n    sorted_video_dir = '/home/ncacord/Desktop/raphael_core/AI_Core/DataOrganizerAI/SortedFiles/Videos'  # Update this path\n    metadata_output_dir = '/home/ncacord/Desktop/raphael_core/AI_Core/DataOrganizerAI/ParsedData/VideoMetadata'  # Update this path\n    if not os.path.exists(metadata_output_dir):\n        os.makedirs(metadata_output_dir)\n    video_files = [filename for filename in os.listdir(sorted_video_dir) if filename.lower().endswith(('.mp4', '.mkv', '.avi', '.mov'))]\n    total_files = len(video_files)\n    processed_files = 0\n    print(\"Video metadata extraction in progress:\")",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "install_requirements",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "def install_requirements(requirements_file):\n    try:\n        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-r', requirements_file])\n        logging.info(\"Successfully installed requirements from {}\".format(requirements_file))\n    except subprocess.CalledProcessError as e:\n        logging.error(\"Failed to install requirements: {}\".format(e))\n        sys.exit(1)\ndef find_requirements_file(start_path):\n    for root, dirs, files in os.walk(start_path):\n        if 'requirements.txt' in files:",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "find_requirements_file",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "def find_requirements_file(start_path):\n    for root, dirs, files in os.walk(start_path):\n        if 'requirements.txt' in files:\n            return os.path.join(root, 'requirements.txt')\n    return None\ndef find_data_dumps_dir(start_path):\n    for root, dirs, files in os.walk(start_path):\n        if 'DataDumps' in dirs:\n            return os.path.join(root, 'DataDumps')\n    return None",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "find_data_dumps_dir",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "def find_data_dumps_dir(start_path):\n    for root, dirs, files in os.walk(start_path):\n        if 'DataDumps' in dirs:\n            return os.path.join(root, 'DataDumps')\n    return None\ndef categorize_file(file):\n    # Define your file categorization logic here\n    file_ext = file.split(\".\")[-1].lower()\n    if file_ext in ['mp3', 'wav', 'aac']:\n        return \"Audio\"",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "categorize_file",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "def categorize_file(file):\n    # Define your file categorization logic here\n    file_ext = file.split(\".\")[-1].lower()\n    if file_ext in ['mp3', 'wav', 'aac']:\n        return \"Audio\"\n    elif file_ext in ['doc', 'docx', 'txt']:\n        return \"Documents\"\n    elif file_ext in ['jpg', 'jpeg', 'png', 'gif']:\n        return \"Images\"\n    elif file_ext == 'pdf':",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "handle_file",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "def handle_file(file, sorted_dir, data_dumps_dir):\n    file_path = os.path.join(data_dumps_dir, file)\n    if os.path.isfile(file_path):\n        try:\n            category = categorize_file(file)\n            category_dir = os.path.join(sorted_dir, category)\n            if not os.path.exists(category_dir):\n                os.makedirs(category_dir)\n            shutil.move(file_path, os.path.join(category_dir, file))\n            logging.info(\"Moved: %s to %s\", file, category)",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "get_folder_size",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "def get_folder_size(folder):\n    total_size = 0\n    for path, _, files in os.walk(folder):\n        for f in files:\n            fp = os.path.join(path, f)\n            total_size += os.path.getsize(fp)\n    return total_size\ndef progress_bar(current, total, start_time, initial_size):\n    elapsed_time = time.time() - start_time\n    completion = current / total",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "progress_bar",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "def progress_bar(current, total, start_time, initial_size):\n    elapsed_time = time.time() - start_time\n    completion = current / total\n    progress = int(completion * 50)\n    remaining_time = (elapsed_time / completion) * (1 - completion) if completion > 0 else 0\n    time_left = time.strftime(\"%H:%M:%S\", time.gmtime(remaining_time))\n    percentage = int(completion * 100)\n    bar = \"[\" + \"#\" * progress + \" \" * (50 - progress) + \"]\"\n    print(f\"\\r{bar} {percentage}% Complete | Time Left: {time_left} | Initial Folder Size: {initial_size} bytes\", end=\"\")\n# Script start",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "log_path",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "log_path = \"file_sorting.log\"\nlogging.basicConfig(filename=log_path, level=logging.INFO, format=\"%(asctime)s %(message)s\")\n# Check for requirements.txt and install requirements\nrequirements_file = find_requirements_file(os.path.expanduser(\"~\"))\nif requirements_file:\n    install_requirements(requirements_file)\n# Find DataDumps directory\ndata_dumps_dir = find_data_dumps_dir(os.path.expanduser(\"~\"))\nif not data_dumps_dir:\n    logging.error(\"DataDumps directory not found.\")",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "requirements_file",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "requirements_file = find_requirements_file(os.path.expanduser(\"~\"))\nif requirements_file:\n    install_requirements(requirements_file)\n# Find DataDumps directory\ndata_dumps_dir = find_data_dumps_dir(os.path.expanduser(\"~\"))\nif not data_dumps_dir:\n    logging.error(\"DataDumps directory not found.\")\n    sys.exit(1)\n# Sorting files in DataDumps\nSORTED_DIR = \"SortedFiles\"",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "data_dumps_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "data_dumps_dir = find_data_dumps_dir(os.path.expanduser(\"~\"))\nif not data_dumps_dir:\n    logging.error(\"DataDumps directory not found.\")\n    sys.exit(1)\n# Sorting files in DataDumps\nSORTED_DIR = \"SortedFiles\"\nsorted_dir = os.path.join(data_dumps_dir, SORTED_DIR)\nif not os.path.exists(sorted_dir):\n    os.makedirs(sorted_dir)\ninitial_size = get_folder_size(data_dumps_dir)",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "SORTED_DIR",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "SORTED_DIR = \"SortedFiles\"\nsorted_dir = os.path.join(data_dumps_dir, SORTED_DIR)\nif not os.path.exists(sorted_dir):\n    os.makedirs(sorted_dir)\ninitial_size = get_folder_size(data_dumps_dir)\nstart_time = time.time()\nfile_count = len(os.listdir(data_dumps_dir))\ncurrent_file = 0\nfor filename in os.listdir(data_dumps_dir):\n    handle_file(filename, sorted_dir, data_dumps_dir)",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "sorted_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "sorted_dir = os.path.join(data_dumps_dir, SORTED_DIR)\nif not os.path.exists(sorted_dir):\n    os.makedirs(sorted_dir)\ninitial_size = get_folder_size(data_dumps_dir)\nstart_time = time.time()\nfile_count = len(os.listdir(data_dumps_dir))\ncurrent_file = 0\nfor filename in os.listdir(data_dumps_dir):\n    handle_file(filename, sorted_dir, data_dumps_dir)\n    current_file += 1",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "initial_size",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "initial_size = get_folder_size(data_dumps_dir)\nstart_time = time.time()\nfile_count = len(os.listdir(data_dumps_dir))\ncurrent_file = 0\nfor filename in os.listdir(data_dumps_dir):\n    handle_file(filename, sorted_dir, data_dumps_dir)\n    current_file += 1\n    progress_bar(current_file, file_count, start_time, initial_size)\nlogging.info(\"Files sorted by type. Check sorting logs for details.\")\n# Script end",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "start_time",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "start_time = time.time()\nfile_count = len(os.listdir(data_dumps_dir))\ncurrent_file = 0\nfor filename in os.listdir(data_dumps_dir):\n    handle_file(filename, sorted_dir, data_dumps_dir)\n    current_file += 1\n    progress_bar(current_file, file_count, start_time, initial_size)\nlogging.info(\"Files sorted by type. Check sorting logs for details.\")\n# Script end",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "file_count",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "file_count = len(os.listdir(data_dumps_dir))\ncurrent_file = 0\nfor filename in os.listdir(data_dumps_dir):\n    handle_file(filename, sorted_dir, data_dumps_dir)\n    current_file += 1\n    progress_bar(current_file, file_count, start_time, initial_size)\nlogging.info(\"Files sorted by type. Check sorting logs for details.\")\n# Script end",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "current_file",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "current_file = 0\nfor filename in os.listdir(data_dumps_dir):\n    handle_file(filename, sorted_dir, data_dumps_dir)\n    current_file += 1\n    progress_bar(current_file, file_count, start_time, initial_size)\nlogging.info(\"Files sorted by type. Check sorting logs for details.\")\n# Script end",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.[Other Scripts].check_requirements",
        "description": "MindMatrix.DataOrganizerAI.Scripts.[Other Scripts].check_requirements",
        "peekOfCode": "def check_requirements():\n    with open('/home/ncacord/Desktop/DataOrganizerAI/requirements.txt', encoding='utf-8') as f:\n        required_packages = [line.strip() for line in f if line.strip()]\n    installed_packages = [pkg.key for pkg in list(pkg_resources.working_set)]\n    missing_packages = set(required_packages) - set(installed_packages)\n    if missing_packages:\n        print(\"Missing packages detected:\")\n        for package in missing_packages:\n            print(f\"- {package}\")\n        choice = input(\"Do you want to install these packages? [Y/n]: \")",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.[Other Scripts].check_requirements",
        "documentation": {}
    },
    {
        "label": "run_parsing_script",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.data_parsing_master",
        "description": "MindMatrix.DataOrganizerAI.Scripts.data_parsing_master",
        "peekOfCode": "def run_parsing_script(script_path, file_type_directory):\n    subprocess.run([\"python\", script_path, file_type_directory])\ndef main():\n    base_dir = '/home/ncacord/Desktop/raphael_core/AI_Core/DataOrganizerAI'\n    sorted_dir = os.path.join(base_dir, 'SortedFiles')\n    for file_type in os.listdir(sorted_dir):\n        file_type_path = os.path.join(sorted_dir, file_type)\n        if file_type == 'Documents':\n            run_parsing_script(os.path.join(base_dir, '/home/ncacord/Desktop/raphael_core/AI_Core/DataOrganizerAI/Scripts/FileParsing/text_parser.py'), file_type_path)\n        elif file_type == 'Images':",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.data_parsing_master",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.data_parsing_master",
        "description": "MindMatrix.DataOrganizerAI.Scripts.data_parsing_master",
        "peekOfCode": "def main():\n    base_dir = '/home/ncacord/Desktop/raphael_core/AI_Core/DataOrganizerAI'\n    sorted_dir = os.path.join(base_dir, 'SortedFiles')\n    for file_type in os.listdir(sorted_dir):\n        file_type_path = os.path.join(sorted_dir, file_type)\n        if file_type == 'Documents':\n            run_parsing_script(os.path.join(base_dir, '/home/ncacord/Desktop/raphael_core/AI_Core/DataOrganizerAI/Scripts/FileParsing/text_parser.py'), file_type_path)\n        elif file_type == 'Images':\n            run_parsing_script(os.path.join(base_dir, '/home/ncacord/Desktop/raphael_core/AI_Core/DataOrganizerAI/Scripts/FileParsing/image_metadata_extractor.py'), file_type_path)\n        elif file_type == 'Audio':",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.data_parsing_master",
        "documentation": {}
    },
    {
        "label": "tokenize",
        "kind": 2,
        "importPath": "PersonaCore.CharacterTraits.utils.preprocessing",
        "description": "PersonaCore.CharacterTraits.utils.preprocessing",
        "peekOfCode": "def tokenize(text):\n    \"\"\"\n    Tokenizes the input text into words.\n    Args:\n    text (str): A string of text to be tokenized.\n    Returns:\n    list: A list of word tokens.\n    \"\"\"\n    return word_tokenize(text)\ndef stem(words):",
        "detail": "PersonaCore.CharacterTraits.utils.preprocessing",
        "documentation": {}
    },
    {
        "label": "stem",
        "kind": 2,
        "importPath": "PersonaCore.CharacterTraits.utils.preprocessing",
        "description": "PersonaCore.CharacterTraits.utils.preprocessing",
        "peekOfCode": "def stem(words):\n    \"\"\"\n    Stems the list of word tokens.\n    Args:\n    words (list): A list of word tokens.\n    Returns:\n    list: A list of stemmed word tokens.\n    \"\"\"\n    stemmer = PorterStemmer()\n    return [stemmer.stem(word) for word in words]",
        "detail": "PersonaCore.CharacterTraits.utils.preprocessing",
        "documentation": {}
    },
    {
        "label": "analyze_traits",
        "kind": 2,
        "importPath": "PersonaCore.CharacterTraits.trait_analysis",
        "description": "PersonaCore.CharacterTraits.trait_analysis",
        "peekOfCode": "def analyze_traits(tokens):\n    \"\"\"\n    Analyzes the tokenized and stemmed text to infer character traits.\n    Args:\n    tokens (list): A list of stemmed word tokens.\n    Returns:\n    dict: A dictionary with trait scores.\n    \"\"\"\n    # Placeholder for the actual trait analysis logic\n    # Here you would implement your analysis algorithm",
        "detail": "PersonaCore.CharacterTraits.trait_analysis",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "PersonaCore.CharacterTraits.trait_analysis",
        "description": "PersonaCore.CharacterTraits.trait_analysis",
        "peekOfCode": "def main():\n    input_text = \"Some example text.\"\n    # Tokenize and stem the input text\n    tokens = tokenize(input_text)\n    stemmed_tokens = stem(tokens)\n    # Proceed with trait analysis using the processed tokens\n    traits = analyze_traits(stemmed_tokens)\n    # Output the results\n    print(json.dumps(traits, indent=4))\nif __name__ == \"__main__\":",
        "detail": "PersonaCore.CharacterTraits.trait_analysis",
        "documentation": {}
    }
]