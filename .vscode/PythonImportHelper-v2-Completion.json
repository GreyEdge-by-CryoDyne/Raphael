[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "magic",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "magic",
        "description": "magic",
        "detail": "magic",
        "documentation": {}
    },
    {
        "label": "EasyID3",
        "importPath": "mutagen.easyid3",
        "description": "mutagen.easyid3",
        "isExtraImport": true,
        "detail": "mutagen.easyid3",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "TAGS",
        "importPath": "PIL.ExifTags",
        "description": "PIL.ExifTags",
        "isExtraImport": true,
        "detail": "PIL.ExifTags",
        "documentation": {}
    },
    {
        "label": "PyPDF2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PyPDF2",
        "description": "PyPDF2",
        "detail": "PyPDF2",
        "documentation": {}
    },
    {
        "label": "VideoFileClip",
        "importPath": "moviepy.editor",
        "description": "moviepy.editor",
        "isExtraImport": true,
        "detail": "moviepy.editor",
        "documentation": {}
    },
    {
        "label": "zipfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zipfile",
        "description": "zipfile",
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "tarfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tarfile",
        "description": "tarfile",
        "detail": "tarfile",
        "documentation": {}
    },
    {
        "label": "rarfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "rarfile",
        "description": "rarfile",
        "detail": "rarfile",
        "documentation": {}
    },
    {
        "label": "psutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "psutil",
        "description": "psutil",
        "detail": "psutil",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "nltk",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "nltk",
        "description": "nltk",
        "detail": "nltk",
        "documentation": {}
    },
    {
        "label": "word_tokenize",
        "importPath": "nltk.tokenize",
        "description": "nltk.tokenize",
        "isExtraImport": true,
        "detail": "nltk.tokenize",
        "documentation": {}
    },
    {
        "label": "PorterStemmer",
        "importPath": "nltk.stem",
        "description": "nltk.stem",
        "isExtraImport": true,
        "detail": "nltk.stem",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "tokenize",
        "importPath": "utils.preprocessing",
        "description": "utils.preprocessing",
        "isExtraImport": true,
        "detail": "utils.preprocessing",
        "documentation": {}
    },
    {
        "label": "stem",
        "importPath": "utils.preprocessing",
        "description": "utils.preprocessing",
        "isExtraImport": true,
        "detail": "utils.preprocessing",
        "documentation": {}
    },
    {
        "label": "backup_data",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.Backup and Recovery Script:.backup_recovery",
        "description": "MindMatrix.DataOrganizerAI.Scripts.Backup and Recovery Script:.backup_recovery",
        "peekOfCode": "def backup_data():\n    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n    backup_path = os.path.join(backup_dir, f'backup_{timestamp}')\n    try:\n        shutil.copytree(data_dir, backup_path)\n        logging.info(f\"Backup created successfully at {backup_path}\")\n    except Exception as e:\n        logging.error(f\"Backup failed: {e}\")\nif __name__ == '__main__':\n    backup_data()",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.Backup and Recovery Script:.backup_recovery",
        "documentation": {}
    },
    {
        "label": "data_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.Backup and Recovery Script:.backup_recovery",
        "description": "MindMatrix.DataOrganizerAI.Scripts.Backup and Recovery Script:.backup_recovery",
        "peekOfCode": "data_dir = 'MindMatrix/DataOrganizerAI'\nbackup_dir = 'MindMatrix/DataOrganizerAI/Backups'\nos.makedirs(backup_dir, exist_ok=True)\ndef backup_data():\n    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n    backup_path = os.path.join(backup_dir, f'backup_{timestamp}')\n    try:\n        shutil.copytree(data_dir, backup_path)\n        logging.info(f\"Backup created successfully at {backup_path}\")\n    except Exception as e:",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.Backup and Recovery Script:.backup_recovery",
        "documentation": {}
    },
    {
        "label": "backup_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.Backup and Recovery Script:.backup_recovery",
        "description": "MindMatrix.DataOrganizerAI.Scripts.Backup and Recovery Script:.backup_recovery",
        "peekOfCode": "backup_dir = 'MindMatrix/DataOrganizerAI/Backups'\nos.makedirs(backup_dir, exist_ok=True)\ndef backup_data():\n    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n    backup_path = os.path.join(backup_dir, f'backup_{timestamp}')\n    try:\n        shutil.copytree(data_dir, backup_path)\n        logging.info(f\"Backup created successfully at {backup_path}\")\n    except Exception as e:\n        logging.error(f\"Backup failed: {e}\")",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.Backup and Recovery Script:.backup_recovery",
        "documentation": {}
    },
    {
        "label": "is_valid_file",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.Data Validation Script:.data_validation",
        "description": "MindMatrix.DataOrganizerAI.Scripts.Data Validation Script:.data_validation",
        "peekOfCode": "def is_valid_file(file_path):\n    try:\n        file_type = magic.from_file(file_path, mime=True)\n        return file_type.startswith('image/') or file_type.startswith('audio/') or \\\n               file_type.startswith('video/') or file_type.startswith('text/') or \\\n               file_type == 'application/pdf'\n    except Exception as e:\n        logging.error(f\"Validation failed for {file_path}: {e}\")\n        return False\ndef validate_data():",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.Data Validation Script:.data_validation",
        "documentation": {}
    },
    {
        "label": "validate_data",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.Data Validation Script:.data_validation",
        "description": "MindMatrix.DataOrganizerAI.Scripts.Data Validation Script:.data_validation",
        "peekOfCode": "def validate_data():\n    for file in os.listdir(data_dir):\n        file_path = os.path.join(data_dir, file)\n        if is_valid_file(file_path):\n            shutil.move(file_path, valid_data_dir)\n        else:\n            shutil.move(file_path, invalid_data_dir)\nif __name__ == '__main__':\n    validate_data()",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.Data Validation Script:.data_validation",
        "documentation": {}
    },
    {
        "label": "data_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.Data Validation Script:.data_validation",
        "description": "MindMatrix.DataOrganizerAI.Scripts.Data Validation Script:.data_validation",
        "peekOfCode": "data_dir = 'MindMatrix/DataOrganizerAI/DataDumps'\nvalid_data_dir = 'MindMatrix/DataOrganizerAI/ValidData'\ninvalid_data_dir = 'MindMatrix/DataOrganizerAI/InvalidData'\nos.makedirs(valid_data_dir, exist_ok=True)\nos.makedirs(invalid_data_dir, exist_ok=True)\ndef is_valid_file(file_path):\n    try:\n        file_type = magic.from_file(file_path, mime=True)\n        return file_type.startswith('image/') or file_type.startswith('audio/') or \\\n               file_type.startswith('video/') or file_type.startswith('text/') or \\",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.Data Validation Script:.data_validation",
        "documentation": {}
    },
    {
        "label": "valid_data_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.Data Validation Script:.data_validation",
        "description": "MindMatrix.DataOrganizerAI.Scripts.Data Validation Script:.data_validation",
        "peekOfCode": "valid_data_dir = 'MindMatrix/DataOrganizerAI/ValidData'\ninvalid_data_dir = 'MindMatrix/DataOrganizerAI/InvalidData'\nos.makedirs(valid_data_dir, exist_ok=True)\nos.makedirs(invalid_data_dir, exist_ok=True)\ndef is_valid_file(file_path):\n    try:\n        file_type = magic.from_file(file_path, mime=True)\n        return file_type.startswith('image/') or file_type.startswith('audio/') or \\\n               file_type.startswith('video/') or file_type.startswith('text/') or \\\n               file_type == 'application/pdf'",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.Data Validation Script:.data_validation",
        "documentation": {}
    },
    {
        "label": "invalid_data_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.Data Validation Script:.data_validation",
        "description": "MindMatrix.DataOrganizerAI.Scripts.Data Validation Script:.data_validation",
        "peekOfCode": "invalid_data_dir = 'MindMatrix/DataOrganizerAI/InvalidData'\nos.makedirs(valid_data_dir, exist_ok=True)\nos.makedirs(invalid_data_dir, exist_ok=True)\ndef is_valid_file(file_path):\n    try:\n        file_type = magic.from_file(file_path, mime=True)\n        return file_type.startswith('image/') or file_type.startswith('audio/') or \\\n               file_type.startswith('video/') or file_type.startswith('text/') or \\\n               file_type == 'application/pdf'\n    except Exception as e:",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.Data Validation Script:.data_validation",
        "documentation": {}
    },
    {
        "label": "extract_audio_metadata",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "peekOfCode": "def extract_audio_metadata(file_path):\n    try:\n        audio_metadata = EasyID3(file_path)\n        return {key: audio_metadata[key][0] for key in audio_metadata}\n    except Exception as e:\n        logging.error(f\"Metadata extraction failed for {file_path}: {e}\")\n        return None\ndef process_audio_files():\n    for file in os.listdir(audio_dir):\n        if file.lower().endswith(('.mp3', '.wav')):  # Add other audio formats as needed",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "process_audio_files",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "peekOfCode": "def process_audio_files():\n    for file in os.listdir(audio_dir):\n        if file.lower().endswith(('.mp3', '.wav')):  # Add other audio formats as needed\n            file_path = os.path.join(audio_dir, file)\n            metadata = extract_audio_metadata(file_path)\n            if metadata:\n                metadata_file = os.path.join(metadata_dir, f\"{os.path.splitext(file)[0]}_metadata.txt\")\n                with open(metadata_file, 'w') as f:\n                    for key, value in metadata.items():\n                        f.write(f\"{key}: {value}\\n\")",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "audio_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "peekOfCode": "audio_dir = 'MindMatrix/DataOrganizerAI/SortedFiles/Audio'\nmetadata_dir = 'MindMatrix/DataOrganizerAI/ParsedData/AudioMetadata'\nos.makedirs(metadata_dir, exist_ok=True)\ndef extract_audio_metadata(file_path):\n    try:\n        audio_metadata = EasyID3(file_path)\n        return {key: audio_metadata[key][0] for key in audio_metadata}\n    except Exception as e:\n        logging.error(f\"Metadata extraction failed for {file_path}: {e}\")\n        return None",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "metadata_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "peekOfCode": "metadata_dir = 'MindMatrix/DataOrganizerAI/ParsedData/AudioMetadata'\nos.makedirs(metadata_dir, exist_ok=True)\ndef extract_audio_metadata(file_path):\n    try:\n        audio_metadata = EasyID3(file_path)\n        return {key: audio_metadata[key][0] for key in audio_metadata}\n    except Exception as e:\n        logging.error(f\"Metadata extraction failed for {file_path}: {e}\")\n        return None\ndef process_audio_files():",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.audio_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "extract_image_metadata",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "peekOfCode": "def extract_image_metadata(file_path):\n    try:\n        image = Image.open(file_path)\n        exif_data = image._getexif()\n        return {TAGS.get(key): exif_data[key] for key in exif_data} if exif_data else {}\n    except Exception as e:\n        logging.error(f\"Metadata extraction failed for {file_path}: {e}\")\n        return None\ndef process_image_files():\n    for file in os.listdir(image_dir):",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "process_image_files",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "peekOfCode": "def process_image_files():\n    for file in os.listdir(image_dir):\n        if file.lower().endswith(('.jpg', '.jpeg', '.png')):  # Add other image formats as needed\n            file_path = os.path.join(image_dir, file)\n            metadata = extract_image_metadata(file_path)\n            if metadata:\n                metadata_file = os.path.join(metadata_dir, f\"{os.path.splitext(file)[0]}_metadata.txt\")\n                with open(metadata_file, 'w') as f:\n                    for key, value in metadata.items():\n                        f.write(f\"{key}: {value}\\n\")",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "image_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "peekOfCode": "image_dir = 'MindMatrix/DataOrganizerAI/SortedFiles/Images'\nmetadata_dir = 'MindMatrix/DataOrganizerAI/ParsedData/ImageMetadata'\nos.makedirs(metadata_dir, exist_ok=True)\ndef extract_image_metadata(file_path):\n    try:\n        image = Image.open(file_path)\n        exif_data = image._getexif()\n        return {TAGS.get(key): exif_data[key] for key in exif_data} if exif_data else {}\n    except Exception as e:\n        logging.error(f\"Metadata extraction failed for {file_path}: {e}\")",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "metadata_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "peekOfCode": "metadata_dir = 'MindMatrix/DataOrganizerAI/ParsedData/ImageMetadata'\nos.makedirs(metadata_dir, exist_ok=True)\ndef extract_image_metadata(file_path):\n    try:\n        image = Image.open(file_path)\n        exif_data = image._getexif()\n        return {TAGS.get(key): exif_data[key] for key in exif_data} if exif_data else {}\n    except Exception as e:\n        logging.error(f\"Metadata extraction failed for {file_path}: {e}\")\n        return None",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.image_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "extract_text_from_pdf",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "peekOfCode": "def extract_text_from_pdf(file_path):\n    try:\n        with open(file_path, 'rb') as file:\n            reader = PyPDF2.PdfFileReader(file)\n            text = ''\n            for page_num in range(reader.numPages):\n                text += reader.getPage(page_num).extractText()\n            return text\n    except Exception as e:\n        logging.error(f\"Text extraction failed for {file_path}: {e}\")",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "documentation": {}
    },
    {
        "label": "process_pdf_files",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "peekOfCode": "def process_pdf_files():\n    for file in os.listdir(pdf_dir):\n        if file.lower().endswith('.pdf'):\n            file_path = os.path.join(pdf_dir, file)\n            text = extract_text_from_pdf(file_path)\n            if text:\n                text_file = os.path.join(text_dir, f\"{os.path.splitext(file)[0]}.txt\")\n                with open(text_file, 'w') as f:\n                    f.write(text)\nif __name__ == '__main__':",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "documentation": {}
    },
    {
        "label": "pdf_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "peekOfCode": "pdf_dir = 'MindMatrix/DataOrganizerAI/SortedFiles/PDFs'\ntext_dir = 'MindMatrix/DataOrganizerAI/ParsedData/TextData'\nos.makedirs(text_dir, exist_ok=True)\ndef extract_text_from_pdf(file_path):\n    try:\n        with open(file_path, 'rb') as file:\n            reader = PyPDF2.PdfFileReader(file)\n            text = ''\n            for page_num in range(reader.numPages):\n                text += reader.getPage(page_num).extractText()",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "documentation": {}
    },
    {
        "label": "text_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "peekOfCode": "text_dir = 'MindMatrix/DataOrganizerAI/ParsedData/TextData'\nos.makedirs(text_dir, exist_ok=True)\ndef extract_text_from_pdf(file_path):\n    try:\n        with open(file_path, 'rb') as file:\n            reader = PyPDF2.PdfFileReader(file)\n            text = ''\n            for page_num in range(reader.numPages):\n                text += reader.getPage(page_num).extractText()\n            return text",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.pdf_text_extractor",
        "documentation": {}
    },
    {
        "label": "parse_text_file",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "peekOfCode": "def parse_text_file(file_path):\n    try:\n        with open(file_path, 'r') as file:\n            return file.read()\n    except Exception as e:\n        logging.error(f\"Text parsing failed for {file_path}: {e}\")\n        return None\ndef process_text_files():\n    for file in os.listdir(text_dir):\n        if file.lower().endswith(('.txt', '.docx')):  # Add other text formats as needed",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "documentation": {}
    },
    {
        "label": "process_text_files",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "peekOfCode": "def process_text_files():\n    for file in os.listdir(text_dir):\n        if file.lower().endswith(('.txt', '.docx')):  # Add other text formats as needed\n            file_path = os.path.join(text_dir, file)\n            text = parse_text_file(file_path)\n            if text:\n                parsed_file = os.path.join(parsed_dir, f\"{os.path.splitext(file)[0]}_parsed.txt\")\n                with open(parsed_file, 'w') as f:\n                    f.write(text)\nif __name__ == '__main__':",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "documentation": {}
    },
    {
        "label": "text_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "peekOfCode": "text_dir = 'MindMatrix/DataOrganizerAI/SortedFiles/Documents'\nparsed_dir = 'MindMatrix/DataOrganizerAI/ParsedData/TextData'\nos.makedirs(parsed_dir, exist_ok=True)\ndef parse_text_file(file_path):\n    try:\n        with open(file_path, 'r') as file:\n            return file.read()\n    except Exception as e:\n        logging.error(f\"Text parsing failed for {file_path}: {e}\")\n        return None",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "documentation": {}
    },
    {
        "label": "parsed_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "peekOfCode": "parsed_dir = 'MindMatrix/DataOrganizerAI/ParsedData/TextData'\nos.makedirs(parsed_dir, exist_ok=True)\ndef parse_text_file(file_path):\n    try:\n        with open(file_path, 'r') as file:\n            return file.read()\n    except Exception as e:\n        logging.error(f\"Text parsing failed for {file_path}: {e}\")\n        return None\ndef process_text_files():",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.text_parser",
        "documentation": {}
    },
    {
        "label": "extract_video_metadata",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "peekOfCode": "def extract_video_metadata(file_path):\n    try:\n        clip = VideoFileClip(file_path)\n        return {\n            \"Duration\": clip.duration,\n            \"FPS\": clip.fps,\n            \"Resolution\": clip.size\n        }\n    except Exception as e:\n        logging.error(f\"Metadata extraction failed for {file_path}: {e}\")",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "process_video_files",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "peekOfCode": "def process_video_files():\n    for file in os.listdir(video_dir):\n        if file.lower().endswith(('.mp4', '.avi')):  # Add other video formats as needed\n            file_path = os.path.join(video_dir, file)\n            metadata = extract_video_metadata(file_path)\n            if metadata:\n                metadata_file = os.path.join(metadata_dir, f\"{os.path.splitext(file)[0]}_metadata.txt\")\n                with open(metadata_file, 'w') as f:\n                    for key, value in metadata.items():\n                        f.write(f\"{key}: {value}\\n\")",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "video_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "peekOfCode": "video_dir = 'MindMatrix/DataOrganizerAI/SortedFiles/Videos'\nmetadata_dir = 'MindMatrix/DataOrganizerAI/ParsedData/VideoMetadata'\nos.makedirs(metadata_dir, exist_ok=True)\ndef extract_video_metadata(file_path):\n    try:\n        clip = VideoFileClip(file_path)\n        return {\n            \"Duration\": clip.duration,\n            \"FPS\": clip.fps,\n            \"Resolution\": clip.size",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "metadata_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "peekOfCode": "metadata_dir = 'MindMatrix/DataOrganizerAI/ParsedData/VideoMetadata'\nos.makedirs(metadata_dir, exist_ok=True)\ndef extract_video_metadata(file_path):\n    try:\n        clip = VideoFileClip(file_path)\n        return {\n            \"Duration\": clip.duration,\n            \"FPS\": clip.fps,\n            \"Resolution\": clip.size\n        }",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileParsing.video_metadata_extractor",
        "documentation": {}
    },
    {
        "label": "uncompress_file",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "def uncompress_file(file_path, destination):\n    try:\n        if file_path.endswith('.zip'):\n            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n                zip_ref.extractall(destination)\n        elif file_path.endswith('.tar'):\n            with tarfile.open(file_path, 'r') as tar_ref:\n                tar_ref.extractall(destination)\n        elif file_path.endswith('.rar'):\n            with rarfile.RarFile(file_path, 'r') as rar_ref:",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "sort_files",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "def sort_files():\n    for file in os.listdir(source_dir):\n        file_path = os.path.join(source_dir, file)\n        file_extension = os.path.splitext(file)[1].lower()\n        # Check if file is an archive and uncompress it\n        if file_extension in archive_formats:\n            if uncompress_file(file_path, source_dir):\n                os.remove(file_path)  # Remove the archive after extraction\n            else:\n                shutil.move(file_path, uncompressible_dir)",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "source_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "source_dir = 'DataDumps'\nsorted_dir = 'MindMatrix/DataOrganizerAI/SortedFiles'\nuncompressible_dir = 'MindMatrix/DataOrganizerAI/Uncompressible'\n# Ensure existence of necessary directories\nos.makedirs(sorted_dir, exist_ok=True)\nos.makedirs(uncompressible_dir, exist_ok=True)\n# Supported file types for sorting\nfile_types = {\n    '.txt': 'Documents',\n    '.pdf': 'PDFs',",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "sorted_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "sorted_dir = 'MindMatrix/DataOrganizerAI/SortedFiles'\nuncompressible_dir = 'MindMatrix/DataOrganizerAI/Uncompressible'\n# Ensure existence of necessary directories\nos.makedirs(sorted_dir, exist_ok=True)\nos.makedirs(uncompressible_dir, exist_ok=True)\n# Supported file types for sorting\nfile_types = {\n    '.txt': 'Documents',\n    '.pdf': 'PDFs',\n    '.jpg': 'Images',",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "uncompressible_dir",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "uncompressible_dir = 'MindMatrix/DataOrganizerAI/Uncompressible'\n# Ensure existence of necessary directories\nos.makedirs(sorted_dir, exist_ok=True)\nos.makedirs(uncompressible_dir, exist_ok=True)\n# Supported file types for sorting\nfile_types = {\n    '.txt': 'Documents',\n    '.pdf': 'PDFs',\n    '.jpg': 'Images',\n    '.png': 'Images',",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "file_types",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "file_types = {\n    '.txt': 'Documents',\n    '.pdf': 'PDFs',\n    '.jpg': 'Images',\n    '.png': 'Images',\n    '.mp3': 'Audio',\n    '.wav': 'Audio',\n    '.mp4': 'Videos',\n    '.avi': 'Videos'\n    # Add other file types as needed",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "archive_formats",
        "kind": 5,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "description": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "peekOfCode": "archive_formats = ['.zip', '.tar', '.rar']\ndef uncompress_file(file_path, destination):\n    try:\n        if file_path.endswith('.zip'):\n            with zipfile.ZipFile(file_path, 'r') as zip_ref:\n                zip_ref.extractall(destination)\n        elif file_path.endswith('.tar'):\n            with tarfile.open(file_path, 'r') as tar_ref:\n                tar_ref.extractall(destination)\n        elif file_path.endswith('.rar'):",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.FileSorting.sort_by_type",
        "documentation": {}
    },
    {
        "label": "monitor_performance",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.Performance Monitoring Script:.performance_monitoring",
        "description": "MindMatrix.DataOrganizerAI.Scripts.Performance Monitoring Script:.performance_monitoring",
        "peekOfCode": "def monitor_performance():\n    cpu_usage = psutil.cpu_percent(interval=1)\n    memory_usage = psutil.virtual_memory().percent\n    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n    logging.info(f\"{timestamp} - CPU Usage: {cpu_usage}%, Memory Usage: {memory_usage}%\")\nif __name__ == '__main__':\n    monitor_performance()",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.Performance Monitoring Script:.performance_monitoring",
        "documentation": {}
    },
    {
        "label": "check_and_install",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.[Other Scripts].check_requirements",
        "description": "MindMatrix.DataOrganizerAI.Scripts.[Other Scripts].check_requirements",
        "peekOfCode": "def check_and_install(package):\n    try:\n        subprocess.run(['pip', 'install', package], check=True)\n    except subprocess.CalledProcessError:\n        print(f\"Failed to install {package}\")\ndef main():\n    requirements = ['mutagen', 'Pillow', 'PyPDF2', 'moviepy']\n    for package in requirements:\n        check_and_install(package)\nif __name__ == '__main__':",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.[Other Scripts].check_requirements",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.[Other Scripts].check_requirements",
        "description": "MindMatrix.DataOrganizerAI.Scripts.[Other Scripts].check_requirements",
        "peekOfCode": "def main():\n    requirements = ['mutagen', 'Pillow', 'PyPDF2', 'moviepy']\n    for package in requirements:\n        check_and_install(package)\nif __name__ == '__main__':\n    main()",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.[Other Scripts].check_requirements",
        "documentation": {}
    },
    {
        "label": "run_parsing_script",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.data_parsing_master",
        "description": "MindMatrix.DataOrganizerAI.Scripts.data_parsing_master",
        "peekOfCode": "def run_parsing_script(script_path, file_type_directory):\n    subprocess.run([\"python\", script_path, file_type_directory])\ndef main():\n    base_dir = '/home/ncacord/Desktop/raphael_core/AI_Core/DataOrganizerAI'\n    sorted_dir = os.path.join(base_dir, 'SortedFiles')\n    for file_type in os.listdir(sorted_dir):\n        file_type_path = os.path.join(sorted_dir, file_type)\n        if file_type == 'Documents':\n            run_parsing_script(os.path.join(base_dir, '/home/ncacord/Desktop/raphael_core/AI_Core/DataOrganizerAI/Scripts/FileParsing/text_parser.py'), file_type_path)\n        elif file_type == 'Images':",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.data_parsing_master",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "MindMatrix.DataOrganizerAI.Scripts.data_parsing_master",
        "description": "MindMatrix.DataOrganizerAI.Scripts.data_parsing_master",
        "peekOfCode": "def main():\n    base_dir = '/home/ncacord/Desktop/raphael_core/AI_Core/DataOrganizerAI'\n    sorted_dir = os.path.join(base_dir, 'SortedFiles')\n    for file_type in os.listdir(sorted_dir):\n        file_type_path = os.path.join(sorted_dir, file_type)\n        if file_type == 'Documents':\n            run_parsing_script(os.path.join(base_dir, '/home/ncacord/Desktop/raphael_core/AI_Core/DataOrganizerAI/Scripts/FileParsing/text_parser.py'), file_type_path)\n        elif file_type == 'Images':\n            run_parsing_script(os.path.join(base_dir, '/home/ncacord/Desktop/raphael_core/AI_Core/DataOrganizerAI/Scripts/FileParsing/image_metadata_extractor.py'), file_type_path)\n        elif file_type == 'Audio':",
        "detail": "MindMatrix.DataOrganizerAI.Scripts.data_parsing_master",
        "documentation": {}
    },
    {
        "label": "tokenize",
        "kind": 2,
        "importPath": "PersonaCore.CharacterTraits.utils.preprocessing",
        "description": "PersonaCore.CharacterTraits.utils.preprocessing",
        "peekOfCode": "def tokenize(text):\n    \"\"\"\n    Tokenizes the input text into words.\n    Args:\n    text (str): A string of text to be tokenized.\n    Returns:\n    list: A list of word tokens.\n    \"\"\"\n    return word_tokenize(text)\ndef stem(words):",
        "detail": "PersonaCore.CharacterTraits.utils.preprocessing",
        "documentation": {}
    },
    {
        "label": "stem",
        "kind": 2,
        "importPath": "PersonaCore.CharacterTraits.utils.preprocessing",
        "description": "PersonaCore.CharacterTraits.utils.preprocessing",
        "peekOfCode": "def stem(words):\n    \"\"\"\n    Stems the list of word tokens.\n    Args:\n    words (list): A list of word tokens.\n    Returns:\n    list: A list of stemmed word tokens.\n    \"\"\"\n    stemmer = PorterStemmer()\n    return [stemmer.stem(word) for word in words]",
        "detail": "PersonaCore.CharacterTraits.utils.preprocessing",
        "documentation": {}
    },
    {
        "label": "analyze_traits",
        "kind": 2,
        "importPath": "PersonaCore.CharacterTraits.trait_analysis",
        "description": "PersonaCore.CharacterTraits.trait_analysis",
        "peekOfCode": "def analyze_traits(tokens):\n    \"\"\"\n    Analyzes the tokenized and stemmed text to infer character traits.\n    Args:\n    tokens (list): A list of stemmed word tokens.\n    Returns:\n    dict: A dictionary with trait scores.\n    \"\"\"\n    # Placeholder for the actual trait analysis logic\n    # Here you would implement your analysis algorithm",
        "detail": "PersonaCore.CharacterTraits.trait_analysis",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "PersonaCore.CharacterTraits.trait_analysis",
        "description": "PersonaCore.CharacterTraits.trait_analysis",
        "peekOfCode": "def main():\n    input_text = \"Some example text.\"\n    # Tokenize and stem the input text\n    tokens = tokenize(input_text)\n    stemmed_tokens = stem(tokens)\n    # Proceed with trait analysis using the processed tokens\n    traits = analyze_traits(stemmed_tokens)\n    # Output the results\n    print(json.dumps(traits, indent=4))\nif __name__ == \"__main__\":",
        "detail": "PersonaCore.CharacterTraits.trait_analysis",
        "documentation": {}
    }
]